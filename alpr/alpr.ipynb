{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import clear_border\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import imutils\n",
    "from imutils import paths\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALPR:\n",
    "    def __init__(self, minAR=3, maxAR=10, debug=False):\n",
    "        # stores min and max aspect ratios for license plates\n",
    "        # debug determines whether or not to display intermediate results\n",
    "        self.minAR = minAR\n",
    "        self.maxAR = maxAR\n",
    "        self.debug = debug\n",
    "        \n",
    "    def debug_imshow(self, title, image, waitKey=False):\n",
    "        # show the image with title if in debug mode\n",
    "        if self.debug:\n",
    "            cv2.imshow(title, image)\n",
    "            \n",
    "            # check to see if we should wait for keypress\n",
    "            if waitKey:\n",
    "                cv2.waitKey(0)\n",
    "                \n",
    "    def locate_license_plate_candidates(self, gray, keep=5):\n",
    "        # perform blackhat morphological operation (reveal dark regions on light background)\n",
    "        # ie license plates\n",
    "        rectKern = cv2.getStructuringElement(cv2.MORPH_RECT, (13, 5))\n",
    "        blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, rectKern)\n",
    "        self.debug_imshow(\"Blackhat\", blackhat)\n",
    "        \n",
    "        # find regions in image that are light\n",
    "        # we clean up the image by filling small holes (black regions) with white\n",
    "        # in order to get a large white region for the license plate\n",
    "        squareKern = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        light = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, squareKern)\n",
    "        light = cv2.threshold(light, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "        self.debug_imshow(\"Light regions\", light)\n",
    "        \n",
    "        # compute gradient of blackhat image in x direction which \n",
    "        # should emphasize the characters on thelicense plate\n",
    "        gradX = cv2.Sobel(blackhat, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n",
    "        gradX = np.absolute(gradX)\n",
    "        (minVal, maxVal) = (np.min(gradX), np.max(gradX))\n",
    "        gradX = 255 * ((gradX - minVal) / (maxVal - minVal))\n",
    "        gradX = gradX.astype(\"uint8\")\n",
    "        self.debug_imshow(\"Scharr\", gradX)\n",
    "        \n",
    "        # blur the gradient representation, applying a closing operation,\n",
    "        # and threshold the image using Otsu's method\n",
    "        \n",
    "        gradX = cv2.GaussianBlur(gradX, (5, 5), 0)\n",
    "        gradX = cv2.morphologyEx(gradX, cv2.MORPH_CLOSE, rectKern)\n",
    "        thresh = cv2.threshold(gradX, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "        self.debug_imshow(\"Grad Thresh\", thresh)\n",
    "        \n",
    "        # perform a series of erosions and dilations to clean up the image\n",
    "        thresh = cv2.erode(thresh, None, iterations=2)\n",
    "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "        self.debug_imshow(\"Grad Erode/Dilate\", thresh)\n",
    "        \n",
    "        # Take bitwise AND of threshold result and light region of the image\n",
    "        thresh = cv2.bitwise_and(thresh, thresh, mask=light)\n",
    "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "        thresh = cv2.erode(thresh, None, iterations=1)\n",
    "        self.debug_imshow(\"Final\", thresh, waitKey=True)\n",
    "        \n",
    "        # find contours in threshold image and sort by size in descending order, \n",
    "        # keeping only largest ones\n",
    "        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:keep]\n",
    "        \n",
    "        return cnts\n",
    "    \n",
    "    def locate_license_plate(self, gray, candidates, clearBorder=False):\n",
    "        # initialize license plate contour and region of interest (ROI)\n",
    "        lpCnt = None\n",
    "        roi = None\n",
    "        \n",
    "        # loop over the license plate candidate contours\n",
    "        for c in candidates:\n",
    "            # compute the bounding box of the contour then use the bounding box to derive the aspect ratio\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            ar = w / float(h)\n",
    "            \n",
    "            # check to see if aspect ratio matches that of license plates\n",
    "            if ar >= self.minAR and ar <= self.maxAR:\n",
    "                # store the license plate contour and extract the license \n",
    "                # plate from the grayscale image and then threshold it\n",
    "                print('yello')\n",
    "                lpCnt = c\n",
    "                licensePlate = gray[y:y + h, x:x + w]\n",
    "                roi = cv2.threshold(licensePlate, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "                \n",
    "                # check to see if we should clear any pixels touching the border, \n",
    "                # which is typically noise\n",
    "                if clearBorder:\n",
    "                    roi = clear_border(roi)\n",
    "                    \n",
    "                # break early sine we have already found license plate region\n",
    "                self.debug_imshow(\"License Plate\", licensePlate)\n",
    "                self.debug_imshow(\"ROI\", roi, waitKey=True)\n",
    "                break\n",
    "        \n",
    "        # return license plate ROI and contour associated\n",
    "        return (roi, lpCnt)\n",
    "    \n",
    "    def build_tesseract_options(self, psm=7):\n",
    "        # PSM mode 7: treat the image as single text line\n",
    "        # tell tesseract to OCR only alphanumeric characters\n",
    "        alphanumeric = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "        options = f\"-c tessedit_char_whitelist={alphanumeric}\"\n",
    "        \n",
    "        # set the PSM mode\n",
    "        options += f\" --psm {psm}\"\n",
    "        \n",
    "        return options\n",
    "                \n",
    "    def find_and_ocr(self, image, psm=7, clearBorder=False):\n",
    "        # initialize license plate text\n",
    "        lpText = None\n",
    "        \n",
    "        # convert image to grayscale, locate all potential licesne plate locations, \n",
    "        # process the candidates and return actual license plate\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        candidates = self.locate_license_plate_candidates(gray)\n",
    "        (lp, lpCnt) = self.locate_license_plate(gray, candidates, clearBorder=clearBorder)\n",
    "        print(\"LP: \", lp)\n",
    "        \n",
    "        # only OCR the license plate if the license plate ROI is not empty\n",
    "        if lp is not None:\n",
    "            # OCR the license plate\n",
    "            options = self.build_tesseract_options(psm=psm)\n",
    "            lpText = pytesseract.image_to_string(lp, config=options)\n",
    "            self.debug_imshow(\"License Plate\", lp)\n",
    "            \n",
    "        # return OCR'd license plate text and the contour associated with the license plate region\n",
    "        return (lpText, lpCnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_text(text):\n",
    "    # strip out non-ASCII text to draw text on image using OpenCV\n",
    "    return \"\".join([c if ord(c) < 128 else \"\" for c in text]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpr = ALPR(debug=True)\n",
    "\n",
    "imagePaths = sorted(list(paths.list_images(\"./images__/\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./images__/0.png', './images__/1.png', './images__/Screen Shot 2022-03-12 at 5.39.31 PM.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-17 12:18:52.291 Python[12127:293908] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to /var/folders/s3/v3l8xgqd3xdgc1ll_pmdv1qr0000gn/T/org.python.python.savedState\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LP:  None\n",
      "None\n",
      "LP:  None\n",
      "None\n",
      "yello\n",
      "LP:  [[255 255 255 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "ABCD012\n",
      "\n",
      "[./images__/Screen Shot 2022-03-12 at 5.39.31 PM.png] ABCD012\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(imagePaths)\n",
    "for imagePath in imagePaths:\n",
    "    # Load image and resize\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = imutils.resize(image, width=600)\n",
    "    \n",
    "    # Apply automatic license plate recognition\n",
    "    (lpText, lpCnt) = alpr.find_and_ocr(image)\n",
    "\n",
    "    print(lpText)\n",
    "\n",
    "    # only continue if license plate successfully OCR'd\n",
    "    if lpText is not None and lpCnt is not None:\n",
    "        # fit bounding box to license plate contour and draw bounding box on license plate\n",
    "        box = cv2.boxPoints(cv2.minAreaRect(lpCnt))\n",
    "        box = box.astype(\"int\")\n",
    "        cv2.drawContours(image, [box], -1, (0, 255, 0), 2)\n",
    "        \n",
    "        # compute unrotated bounding box for the license plate and draw OCR'd license plate text on the image\n",
    "        (x, y, w, h) = cv2.boundingRect(lpCnt)\n",
    "        cv2.putText(image, cleanup_text(lpText), (x, y - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "        \n",
    "        # show the output ANPR image\n",
    "        print(f\"[{imagePath}] {lpText}\")\n",
    "        cv2.imshow(f\"{imagePath}\", image)\n",
    "        cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f08a8da2d60557dc9d6c8035408c492cf09806f68f70de1bb99a8e4e26df45a"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
